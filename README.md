# final_project2_deep_learning
### Student: Christopher Mastrangelo

## Neural Network word pattern recognition using Word2Vec for Python

This project will attempt to answer questions like these: "Why do spell checkers never work for me?"  

Why is it when I text people on my phone, the suggested word never guesses what I want to say next?  Maybe not all the time, but it seems like more often than not, the word suggestions generated by an AI algorithm guess wrong.  Is it because they are trained on coda from classic English writing sources rather than a writing style that matches my own?

Would it be possible to use examples of my own writing to train a machine learning (unsupervised neural network) word embedding algorithm to generate the list of next words? 

If I train the neural network on examples of my own writing could I get a better guess for the next suggested word? 

Word2Vec converts words into decimal number representations because neural networks only work on numeric data. In addition to creating a word embedding algorithm, the neural network uses word "vectors" to group words into associations.  

What information can be learned by analyzing a vector diagram of my own writing?  Are some words more common?  Do I use  different vocabulary than the general English speaking population?

<hr>

### Data Source - sentences from my own email collection.

Code source- the python code for creating and training a model already exists in this GitHub repository

https://github.com/Eligijus112/word-embedding-creation

which is owned by the author (Eligijus Bujokas) of an article which explains how to build the model step  by step on a relatively small set of sentences. Here is a link to the article:

https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8

![image](https://user-images.githubusercontent.com/86205000/142961015-928aa068-3485-4554-8b37-2b33955335de.png)

<b>ETL</b> might be a little challenging - use web scraping to pull in text from emails and tokenize it into sentences so it can be fed in one sentence at a time to the algorithm.

<hr>
<b>Proposal</b>- after getting the model from the article working, then train a new copy of the model using sentences taken from examples of my own writing. 

<b>Visualizations</b>- create a 2-dimensional model of the word vectors showing groupings of associated words

<b>Implementation</b> - after training the model, determine how to apply it in "real life" by implementing an interactive simple "next word guessing" program in Python.

